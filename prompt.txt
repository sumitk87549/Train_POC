can you create a python script to which I can pass sample_text cleaned_text + segregated_text, single final output file (cleaning of distributor's data, publisher and printer's data, useless characters, page numbers etc, remain only story or main content)  (segretion in different section of book (like acknowledgement, glossary, index, appendix, references, preface etc, maked with special characters and  section TITLE. I already have training data (cleaned_text.txt and segregated-marked.txt). I want the script to run like this ''' python sc.py --model deepseek-r1:1.5b -e <extracted txt file_path> -f <final_text.txt> ''' and the script will (pull model from ollama if not available) train the model to give me similar kind of cleaning and segregation when asked for cleaning like in 'readlyte mode' next time. I want you to handle 'how to train model' and 'how the trained model will be saved' by yourself, but I want you to use AI models from ollama only.
I have final cleaned and segregated file and a sample extracted file in @/PROCESSED folder. I want ollama model (deepseek-r1:1.5b) to get trained to , when given extracted text like @/PROCESSED/extracted_text.txt it clean + segregate it like in @/PROCESSED/CLEAN_SEGREGATED_FINAL.txt .


YO SEM, we did enough talks on collapse, drugs , dopamine etc. I am working now and I think the SOBER Sumit is coming back at work, can you give me real detailed tips to make him work like he has done drugs (little euphoric,  little-bit extra focused, forget useless points etc.) I know I asked you this before, but this time whatever you are going to tell will be followed-as-it-is. so try to give me real-life tips to bring good qualities of high Sumit (good qualities only that can help me in working or coding) in SOBER SUMIT.
